{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T14:17:52.738466Z",
     "iopub.status.busy": "2025-02-06T14:17:52.738145Z",
     "iopub.status.idle": "2025-02-06T14:18:07.347773Z",
     "shell.execute_reply": "2025-02-06T14:18:07.347127Z",
     "shell.execute_reply.started": "2025-02-06T14:17:52.738437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T14:18:11.056706Z",
     "iopub.status.busy": "2025-02-06T14:18:11.056426Z",
     "iopub.status.idle": "2025-02-06T14:18:11.061170Z",
     "shell.execute_reply": "2025-02-06T14:18:11.060259Z",
     "shell.execute_reply.started": "2025-02-06T14:18:11.056684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T14:18:15.814621Z",
     "iopub.status.busy": "2025-02-06T14:18:15.814340Z",
     "iopub.status.idle": "2025-02-06T14:18:15.901016Z",
     "shell.execute_reply": "2025-02-06T14:18:15.900040Z",
     "shell.execute_reply.started": "2025-02-06T14:18:15.814600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'3D objects': np.int64(0), 'Algorithm': np.int64(1), 'Area chart': np.int64(2), 'Bar plots': np.int64(3), 'Block diagram': np.int64(4), 'Box plot': np.int64(5), 'Bubble Chart': np.int64(6), 'Confusion matrix': np.int64(7), 'Contour plot': np.int64(8), 'Flow chart': np.int64(9), 'Geographic map': np.int64(10), 'Graph plots': np.int64(11), 'Heat map': np.int64(12), 'Histogram': np.int64(13), 'Mask': np.int64(14), 'Medical images': np.int64(15), 'Natural images': np.int64(16), 'Pareto charts': np.int64(17), 'Pie chart': np.int64(18), 'Polar plot': np.int64(19), 'Radar chart': np.int64(20), 'Scatter plot': np.int64(21), 'Sketches': np.int64(22), 'Surface plot': np.int64(23), 'Tables': np.int64(24), 'Tree Diagram': np.int64(25), 'Vector plot': np.int64(26), 'Venn Diagram': np.int64(27)}\n",
      "Train DataFrame:\n",
      "                              Image_Name       Label    Set  Label_Encoded  \\\n",
      "0   2014_06909662-Figure5-1subFig-2.png  3D objects  train              0   \n",
      "1   2013_06619122-Figure3-1subFig-2.png  3D objects  train              0   \n",
      "2   2015_07298623-Figure4-1subFig-3.png  3D objects  train              0   \n",
      "3   2015_07298623-Figure4-1subFig-2.png  3D objects  train              0   \n",
      "4  2015_07299029-Figure12-1subFig-6.png  3D objects  train              0   \n",
      "\n",
      "                                          Image_Path  \n",
      "0  /data/hdd1/users/kmparmp/DocFigure/images/2014...  \n",
      "1  /data/hdd1/users/kmparmp/DocFigure/images/2013...  \n",
      "2  /data/hdd1/users/kmparmp/DocFigure/images/2015...  \n",
      "3  /data/hdd1/users/kmparmp/DocFigure/images/2015...  \n",
      "4  /data/hdd1/users/kmparmp/DocFigure/images/2015...  \n",
      "\n",
      "Test DataFrame:\n",
      "                             Image_Name       Label   Set  Label_Encoded  \\\n",
      "0  2014_06909689-Figure3-1subFig-2.png  3D objects  test              0   \n",
      "1  2000_00854933-Figure8-1subFig-1.png  3D objects  test              0   \n",
      "2  2015_07298843-Figure6-1subFig-5.png  3D objects  test              0   \n",
      "3  2007_04270220-Figure1-1subFig-1.png  3D objects  test              0   \n",
      "4  2009_05206603-Figure8-1subFig-4.png  3D objects  test              0   \n",
      "\n",
      "                                          Image_Path  \n",
      "0  /data/hdd1/users/kmparmp/DocFigure/images/2014...  \n",
      "1  /data/hdd1/users/kmparmp/DocFigure/images/2000...  \n",
      "2  /data/hdd1/users/kmparmp/DocFigure/images/2015...  \n",
      "3  /data/hdd1/users/kmparmp/DocFigure/images/2007...  \n",
      "4  /data/hdd1/users/kmparmp/DocFigure/images/2009...  \n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "DATA_DIR = \"/data/hdd1/users/kmparmp/DocFigure/annotation\"\n",
    "IMAGE_DIR = \"/data/hdd1/users/kmparmp/DocFigure/images\"\n",
    "\n",
    "train_labels_file = os.path.join(DATA_DIR, \"train.txt\")\n",
    "test_labels_file = os.path.join(DATA_DIR, \"test.txt\")\n",
    "\n",
    "# Function to load labels into a DataFrame\n",
    "def load_labels(file_path: str) -> pd.DataFrame:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = [line.strip().split(\", \") for line in file if \", \" in line]\n",
    "    \n",
    "    return pd.DataFrame(data, columns=[\"Image_Name\", \"Label\"])\n",
    "\n",
    "# Load train and test labels\n",
    "train_df = load_labels(train_labels_file)\n",
    "test_df = load_labels(test_labels_file)\n",
    "\n",
    "# Add dataset type\n",
    "train_df[\"Set\"] = \"train\"\n",
    "test_df[\"Set\"] = \"test\"\n",
    "\n",
    "# Encode labels using the same encoder for both sets\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"Label_Encoded\"] = label_encoder.fit_transform(train_df[\"Label\"])\n",
    "test_df[\"Label_Encoded\"] = label_encoder.transform(test_df[\"Label\"])  # Use same encoding\n",
    "\n",
    "# Print label mapping\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "# Add full image paths\n",
    "train_df[\"Image_Path\"] = train_df[\"Image_Name\"].apply(lambda x: os.path.join(IMAGE_DIR, x))\n",
    "test_df[\"Image_Path\"] = test_df[\"Image_Name\"].apply(lambda x: os.path.join(IMAGE_DIR, x))\n",
    "\n",
    "# Print to verify\n",
    "print(\"Train DataFrame:\\n\", train_df.head())\n",
    "print(\"\\nTest DataFrame:\\n\", test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T14:18:20.528833Z",
     "iopub.status.busy": "2025-02-06T14:18:20.528553Z",
     "iopub.status.idle": "2025-02-06T14:18:22.088050Z",
     "shell.execute_reply": "2025-02-06T14:18:22.087367Z",
     "shell.execute_reply.started": "2025-02-06T14:18:20.528811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained VGG model\n",
    "vgg_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "vgg_model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Remove the last fully connected layer to get FC-CNN features\n",
    "fc_cnn_model = torch.nn.Sequential(*list(vgg_model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T14:18:33.187993Z",
     "iopub.status.busy": "2025-02-06T14:18:33.187645Z",
     "iopub.status.idle": "2025-02-06T15:03:00.158357Z",
     "shell.execute_reply": "2025-02-06T15:03:00.156766Z",
     "shell.execute_reply.started": "2025-02-06T14:18:33.187960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to extract FC-CNN features\n",
    "def extract_fc_cnn_features(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Extract features\n",
    "    with torch.no_grad():\n",
    "        features = fc_cnn_model(image_tensor)\n",
    "    \n",
    "    return features.squeeze().numpy()\n",
    "\n",
    "# Function to extract FV-CNN features (simplified version)\n",
    "def extract_fv_cnn_features(image_path):\n",
    "    # For simplicity, we use the same VGG model but extract features from the last convolutional layer\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    # Extract features from the last convolutional layer\n",
    "    with torch.no_grad():\n",
    "        conv_features = vgg_model.features(image_tensor)\n",
    "    \n",
    "    # Flatten and return the features\n",
    "    return conv_features.squeeze().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hdd1/users/kmparmp/miniconda3/envs/doc_figure/lib/python3.12/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/data/hdd1/users/kmparmp/miniconda3/envs/doc_figure/lib/python3.12/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/data/hdd1/users/kmparmp/miniconda3/envs/doc_figure/lib/python3.12/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/data/hdd1/users/kmparmp/miniconda3/envs/doc_figure/lib/python3.12/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Extract features for all images\n",
    "train_df[\"FC_CNN_Features\"] = train_df[\"Image_Path\"].apply(extract_fc_cnn_features)\n",
    "train_df[\"FV_CNN_Features\"] = train_df[\"Image_Path\"].apply(extract_fv_cnn_features)\n",
    "\n",
    "test_df[\"FC_CNN_Features\"] = test_df[\"Image_Path\"].apply(extract_fc_cnn_features)\n",
    "test_df[\"FV_CNN_Features\"] = test_df[\"Image_Path\"].apply(extract_fv_cnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Combine FC-CNN and FV-CNN features\n",
    "def combine_features(row):\n",
    "    fc_features = row[\"FC_CNN_Features\"].flatten()\n",
    "    fv_features = row[\"FV_CNN_Features\"].flatten()\n",
    "    return np.concatenate((fc_features, fv_features))\n",
    "\n",
    "\n",
    "train_df[\"Combined_Features\"] = train_df.apply(combine_features, axis=1)\n",
    "test_df[\"Combined_Features\"] = test_df.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare data for training\n",
    "X_train = np.array(train_df[\"Combined_Features\"].tolist())\n",
    "y_train = train_df[\"Label_Encoded\"]\n",
    "\n",
    "X_test = np.array(test_df[\"Combined_Features\"].tolist())\n",
    "y_test = test_df[\"Label_Encoded\"]\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_classifier = OneVsRestClassifier(SVC(kernel='linear', C=1))\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svm_gvv_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = \"svm_gvv_model.pkl\"\n",
    "joblib.dump(svm_classifier, model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6610710,
     "sourceId": 10672837,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "doc_figure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
